{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443b989-5a71-455f-9a59-9963338634ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx.schedulers.slurm_scheduler 2025-08-29 15:37:35 INFO unable to get job info for `monarch-ubuntu` with `squeue` (squeue: error: Invalid job id: monarch-ubuntu\n",
      "), trying `sacct`\n",
      "torchx.schedulers.slurm_scheduler 2025-08-29 15:37:35 INFO unable to get job info for `monarch-ubuntu` with `sacct` (sacct: fatal: Bad job/step specified: monarch-ubuntu\n",
      ")\n",
      "monarch.tools.commands 2025-08-29 15:37:35 INFO no existing RUNNING server `slurm:///monarch-ubuntu` creating new one...\n",
      "torchx.runner.api 2025-08-29 15:37:35 INFO Tracker configurations: {}\n",
      "torchx.runner.api 2025-08-29 15:37:35 INFO Checking for changes in workspace `/home/ubuntu/ahmads/monarch/examples`...\n",
      "torchx.runner.api 2025-08-29 15:37:35 INFO To disable workspaces pass: --workspace=\"\" from CLI or workspace=None programmatically.\n",
      "torchx.runner.api 2025-08-29 15:37:35 INFO Reusing original image `monarch_default_workspace:latest` for role[0]=mesh0. Either a patch was built or no changes to workspace was detected.\n",
      "monarch.tools.commands 2025-08-29 15:37:35 INFO created new `slurm:///380` waiting for it to be ready...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahmad: {'requeue': None, 'ntasks-per-node': '1', 'cpus-per-task': '48', 'mem': '186777', 'gpus-per-task': '4', 'ntasks': '1'}\n",
      "Ahmad: {'requeue': None, 'ntasks-per-node': '1', 'cpus-per-task': '48', 'mem': '186777', 'gpus-per-task': '4', 'ntasks': '1'}\n",
      "Waiting for slurm:///380 to be RUNNING (current: PENDING); will check again in 5.0 seconds. Total wait time: 0:00:10.055560\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "slurm.utils 2025-08-29 15:37:50 INFO \n",
      "===== Server Info =====\n",
      "{\n",
      "  \"name\": \"380\",\n",
      "  \"server_handle\": \"slurm:///380\",\n",
      "  \"state\": \"RUNNING\",\n",
      "  \"meshes\": {\n",
      "    \"mesh0\": {\n",
      "      \"host_type\": \"__UNSET__\",\n",
      "      \"hosts\": 2,\n",
      "      \"gpus\": -1,\n",
      "      \"hostnames\": [\n",
      "        \"gpu-queue-st-gpu-compute-1\",\n",
      "        \"gpu-queue-st-gpu-compute-2\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "monarch._src.actor.allocator 2025-08-29 15:37:50 INFO no match label `procmesh.monarch.meta.com/name` specified in alloc constraints\n",
      "monarch._src.actor.allocator 2025-08-29 15:37:50 INFO found a single proc mesh `mesh0` in slurm:///380, will allocate on it\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO no AF_INET6 address that can bind TCP sockets for `gpu-queue-st-gpu-compute-1:26600` (error: [Errno -5] No address associated with hostname)\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO resolved AF_INET address `10.0.2.140:26600` for `gpu-queue-st-gpu-compute-1:26600`\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO no AF_INET6 address that can bind TCP sockets for `gpu-queue-st-gpu-compute-2:26600` (error: [Errno -5] No address associated with hostname)\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO resolved AF_INET address `10.0.2.45:26600` for `gpu-queue-st-gpu-compute-2:26600`\n",
      "monarch._src.actor.allocator 2025-08-29 15:37:50 INFO initializing alloc on remote allocator addresses: ['tcp!10.0.2.140:26600', 'tcp!10.0.2.45:26600']\n",
      "monarch._src.actor.allocator 2025-08-29 15:37:50 INFO no match label `procmesh.monarch.meta.com/name` specified in alloc constraints\n",
      "monarch._src.actor.allocator 2025-08-29 15:37:50 INFO found a single proc mesh `mesh0` in slurm:///380, will allocate on it\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO no AF_INET6 address that can bind TCP sockets for `gpu-queue-st-gpu-compute-1:26600` (error: [Errno -5] No address associated with hostname)\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO resolved AF_INET address `10.0.2.140:26600` for `gpu-queue-st-gpu-compute-1:26600`\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO no AF_INET6 address that can bind TCP sockets for `gpu-queue-st-gpu-compute-2:26600` (error: [Errno -5] No address associated with hostname)\n",
      "monarch.tools.network 2025-08-29 15:37:50 INFO resolved AF_INET address `10.0.2.45:26600` for `gpu-queue-st-gpu-compute-2:26600`\n",
      "monarch._src.actor.allocator 2025-08-29 15:37:50 INFO initializing alloc on remote allocator addresses: ['tcp!10.0.2.140:26600', 'tcp!10.0.2.45:26600']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New job `slurm:///380` is ready to serve.\n",
      "\u001b[36m>>> Aggregated Logs (2025-08-29 15:37:55) >>>\u001b[0m\n",
      "\u001b[33m[8 similar log lines]\u001b[0m self.rank=6 Initializing torch distributed\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7\n",
      "\u001b[33m[8 similar log lines]\u001b[0m self.rank=0 Finished initializing torch distributed\n",
      "\u001b[33m[8 similar log lines]\u001b[0m self.rank=0 Running basic DDP example\n",
      "\u001b[33m[8 similar log lines]\u001b[0m self.rank=0 local_rank=0\n",
      "\u001b[36m<<< Aggregated Logs (2025-08-29 15:37:58) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-08-29 15:37:58) >>>\u001b[0m\n",
      "\u001b[33m[1 similar log lines]\u001b[0m self.rank=4 Finished running basic DDP example\n",
      "\u001b[36m<<< Aggregated Logs (2025-08-29 15:38:02) <<<\u001b[0m\n",
      "\n",
      "DDP example completed successfully!\n",
      "\u001b[36m>>> Aggregated Logs (2025-08-29 15:38:02) >>>\u001b[0m\n",
      "\u001b[33m[7 similar log lines]\u001b[0m self.rank=6 Finished running basic DDP example\n",
      "\u001b[33m[8 similar log lines]\u001b[0m self.rank=0 Cleaning up torch distributed\n",
      "\u001b[36m<<< Aggregated Logs (2025-08-29 15:38:02) <<<\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.\n",
    "\n",
    "# @noautodeps\n",
    "# pyre-ignore-all-errors\n",
    "\n",
    "import argparse\n",
    "import asyncio\n",
    "import getpass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import socket\n",
    "\n",
    "import cloudpickle\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monarch._rust_bindings.monarch_hyperactor.alloc import AllocConstraints, AllocSpec\n",
    "from monarch.actor import ProcMesh\n",
    "from monarch.tools import commands\n",
    "from monarch.tools.components import hyperactor\n",
    "from monarch.tools.config import Config, UnnamedAppDef\n",
    "from monarch._src.actor.allocator import (\n",
    "    RemoteAllocator,\n",
    "    StaticRemoteAllocInitializer,\n",
    "    TorchXRemoteAllocInitializer,\n",
    ")\n",
    "from monarch.actor import Actor, current_rank, current_size, endpoint\n",
    "from monarch.actor import Actor, current_rank, endpoint, proc_mesh\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from example_actors.compute_world_size_actor import TestActor\n",
    "from slurm.utils import get_appdef, get_server_info, create_proc_mesh\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(name)s %(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# TODO: Remove and replace with utils.setup_env_for_distributed once trunk is healthy.\n",
    "def _find_free_port() -> int:\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((\"localhost\", 0))\n",
    "        addr = s.getsockname()\n",
    "        port = addr[1]\n",
    "        return port\n",
    "\n",
    "\n",
    "class _TorchDistributedInitActor(Actor):\n",
    "    def __init__(self) -> None:\n",
    "        self.rank: int = current_rank().rank\n",
    "\n",
    "    @endpoint\n",
    "    def get_host_port(self) -> tuple[str, int]:\n",
    "        return (socket.gethostname(), _find_free_port())\n",
    "\n",
    "    @endpoint\n",
    "    def setup_env(self, master_addr: str, master_port: int) -> None:\n",
    "        cr = current_rank()\n",
    "        # Assume last dimension is the local rank.\n",
    "        last_label = cr.shape.labels[-1]\n",
    "        local_world_size = cr.size(last_label)\n",
    "        world_size = len(cr)\n",
    "        global_rank = cr.rank\n",
    "        local_rank = min(world_size, global_rank % local_world_size)\n",
    "        group_rank = global_rank // local_world_size\n",
    "        group_world_size = (world_size + local_world_size - 1) // local_world_size\n",
    "        env = {\n",
    "            \"MASTER_ADDR\": master_addr,\n",
    "            \"MASTER_PORT\": str(master_port),\n",
    "            \"RANK\": str(global_rank),\n",
    "            \"LOCAL_RANK\": str(local_rank),\n",
    "            \"LOCAL_WORLD_SIZE\": str(local_world_size),\n",
    "            \"GROUP_RANK\": str(group_rank),\n",
    "            \"GROUP_WORLD_SIZE\": str(group_world_size),\n",
    "            \"ROLE_RANK\": str(global_rank),\n",
    "            \"ROLE_WORLD_SIZE\": str(world_size),\n",
    "            \"ROLE_NAME\": \"rank\",\n",
    "            \"WORLD_SIZE\": str(world_size),\n",
    "        }\n",
    "        os.environ.update(env)\n",
    "\n",
    "\n",
    "async def setup_env_for_distributed(\n",
    "    proc_mesh: ProcMesh,\n",
    "    master_addr: str | None = None,\n",
    "    master_port: int | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Sets up environment variables for pytorch distributed.\n",
    "    It selects a random proc in the proc_mesh to be the master node.\n",
    "    It sets enviornment variables like RANK, LOCAL_RANK, WORLD_SIZE, etc.\n",
    "    If master_addr and master_port are None, it will automatically select a master node and port.\n",
    "    \"\"\"\n",
    "    assert (master_addr is None) == (\n",
    "        master_port is None\n",
    "    ), \"Either both master_addr and master_port must be specified or neither must be specified.\"\n",
    "    am = await proc_mesh.spawn(\"_TorchDistributedInitActor\", _TorchDistributedInitActor)\n",
    "    if master_addr is None:\n",
    "        # We use call instead of call_one because call_one can't handle tuple return types.\n",
    "        vm = await am.flatten(\"rank\").slice(rank=0).get_host_port.call()\n",
    "        master_addr, master_port = vm.item()\n",
    "    assert master_port is not None, \"master_port should not be None here.\"\n",
    "    await am.setup_env.call(master_addr, master_port)\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    \"\"\"A simple toy model for demonstration purposes.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "class DDPActor(Actor):\n",
    "    \"\"\"This Actor wraps the basic functionality from Torch's DDP example.\n",
    "\n",
    "    Conveniently, all of the methods we need are already laid out for us,\n",
    "    so we can just wrap them in the usual Actor endpoint semantic with some\n",
    "    light modifications.\n",
    "\n",
    "    Adapted from: https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rank = current_rank().rank\n",
    "\n",
    "    def _rprint(self, msg):\n",
    "        \"\"\"Helper method to print with rank information.\"\"\"\n",
    "        print(f\"{self.rank=} {msg}\")\n",
    "\n",
    "    @endpoint\n",
    "    async def setup(self):\n",
    "        \"\"\"Initialize the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Initializing torch distributed\")\n",
    "\n",
    "        WORLD_SIZE = int(os.environ[\"WORLD_SIZE\"])\n",
    "        # initialize the process group\n",
    "        dist.init_process_group(\"gloo\", rank=self.rank, world_size=WORLD_SIZE)\n",
    "        self._rprint(\"Finished initializing torch distributed\")\n",
    "\n",
    "    @endpoint\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Cleaning up torch distributed\")\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    @endpoint\n",
    "    async def demo_basic(self):\n",
    "        \"\"\"Run a basic DDP training example.\"\"\"\n",
    "        self._rprint(\"Running basic DDP example\")\n",
    "\n",
    "        # create model and move it to GPU with id rank\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        self._rprint(f\"{local_rank=}\")\n",
    "        model = ToyModel().to(local_rank)\n",
    "        ddp_model = DDP(model, device_ids=[local_rank])\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ddp_model(torch.randn(20, 10))\n",
    "        labels = torch.randn(20, 5).to(local_rank)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"{self.rank=} Finished running basic DDP example\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    num_hosts = 2\n",
    "    appdef = await get_appdef(num_hosts)\n",
    "    server_info = await get_server_info(appdef)\n",
    "\n",
    "    try:\n",
    "        proc_mesh = await create_proc_mesh(num_hosts, appdef, server_info)\n",
    "\n",
    "        ddp_actor = await proc_mesh.spawn(\"ddp_actor\", DDPActor)\n",
    "\n",
    "        await setup_env_for_distributed(proc_mesh)\n",
    "\n",
    "        await ddp_actor.setup.call()\n",
    "        await ddp_actor.demo_basic.call()\n",
    "        await ddp_actor.cleanup.call()\n",
    "\n",
    "        print(\"DDP example completed successfully!\")\n",
    "\n",
    "    finally:\n",
    "        commands.kill(f\"slurm:///{server_info.name}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fcfc7-3561-43bd-9945-278fb488e0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahmads-nightly2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
